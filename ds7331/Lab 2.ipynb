{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import Libraries and Alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from dataframe_column_identifier import DataFrameColumnIdentifier\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Intiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Cleansing and preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115232, 38), (115232, 70))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Init\n",
    "url=\"https://raw.githubusercontent.com/bensonnd/msds/master/ds7331/data/hotel_bookings.csv\"\n",
    "hotel = pd.read_csv(url)\n",
    "\n",
    "# Data Cleaning Feature Engineering\n",
    "#converting arrival y/m/d columns to a singular arrival date column\n",
    "hotel['arrival_date'] = pd.to_datetime([f'{y}-{m}-{d}' for y, m, d in zip(hotel.arrival_date_year,\n",
    "                                                                          hotel.arrival_date_month,\n",
    "                                                                          hotel.arrival_date_day_of_month)])\n",
    "\n",
    "# source:\n",
    "# https://stackoverflow.com/questions/54487059/pandas-how-to-create-a-single-date-column-from-columns-containing-year-month\n",
    "\n",
    "# add `departure_date` and `length_of_stay`\n",
    "hotel['length_of_stay'] = hotel[\"stays_in_weekend_nights\"] + hotel[\"stays_in_week_nights\"]\n",
    "\n",
    "# set `length_of_stay` as a pandas time delta\n",
    "length = hotel['length_of_stay'].apply(np.ceil).apply(lambda x: pd.Timedelta(x, unit='D'))\n",
    "\n",
    "hotel['departure_date'] = hotel['arrival_date'] + length\n",
    "\n",
    "# source:\n",
    "# https://stackoverflow.com/questions/42768649/add-days-to-date-in-pandas\n",
    "\n",
    "\n",
    "# Adding total_revenue column to the data frame\n",
    "hotel[\"total_revenue\"] = abs(hotel[\"adr\"]) * hotel[\"length_of_stay\"]\n",
    "\n",
    "# Adding the cancelation rate by country\n",
    "hotel['is_canceled_int'] = pd.to_numeric(hotel['is_canceled'])\n",
    "\n",
    "contry_cancellation_rate_df = pd.DataFrame(hotel.groupby(['country'])['is_canceled_int'].count())\n",
    "\n",
    "contry_cancellation_rate_df.columns = ['country_count']\n",
    "contry_cancellation_rate_df['cancelations'] = pd.DataFrame(hotel.groupby(['country'])['is_canceled_int'].sum())\n",
    "\n",
    "contry_cancellation_rate_df['country_cancelation_rate'] = contry_cancellation_rate_df['cancelations'] / contry_cancellation_rate_df['country_count']\n",
    "\n",
    "hotel = hotel.join(contry_cancellation_rate_df, on='country')\n",
    "\n",
    "total_cancelations = hotel.is_canceled_int.sum()\n",
    "\n",
    "hotel = hotel.drop(['country_count','cancelations','is_canceled_int'], axis=1)\n",
    "\n",
    "# Changing Stays in Weeknights and Weekend nights to Boolean\n",
    "hotel['stays_in_week_nights_cat'] = np.where(hotel['stays_in_week_nights']>0, 1, 0)\n",
    "hotel['stays_in_weekend_nights_cat'] = np.where(hotel['stays_in_weekend_nights']>0, 1, 0)\n",
    "\n",
    "# Dropping redundant columns\n",
    "hotel = hotel.drop(['arrival_date_year','arrival_date_month','arrival_date_day_of_month'], axis=1)\n",
    "\n",
    "# Finding missing values\n",
    "hotel.columns[hotel.isnull().any()].tolist()\n",
    "\n",
    "# Replacing missing values for categorical to \"Unknown\"\n",
    "cat_cols = [\"country\",\"agent\",\"company\"]\n",
    "hotel[cat_cols] = hotel[cat_cols].replace({np.nan:\"Unknown\"})\n",
    "\n",
    "# Replacing missing values for continuous to 0\n",
    "con_cols = [\"children\", \"country_cancelation_rate\"]\n",
    "hotel[con_cols] = hotel[con_cols].replace({np.nan:0})\n",
    "\n",
    "# Source:\n",
    "# https://stackoverflow.com/questions/45416684/python-pandas-replace-multiple-columns-zero-to-nan\n",
    "\n",
    "# converting these columns to string type\n",
    "hotel[cat_cols] = hotel[cat_cols].astype(str)\n",
    "\n",
    "#make all adr values positive. (only one is actually negative.)\n",
    "hotel['adr'] = hotel['adr'].abs()\n",
    "\n",
    "# list of continuous attributes\n",
    "hotel_continuous = ['lead_time', 'arrival_date_week_number', 'stays_in_weekend_nights', 'stays_in_week_nights', 'length_of_stay', \n",
    "                      'previous_cancellations', 'previous_bookings_not_canceled', 'booking_changes','days_in_waiting_list', 'adr', \n",
    "                      'required_car_parking_spaces', 'total_of_special_requests', 'adults', 'children', 'babies','total_revenue', 'country_cancelation_rate']\n",
    "\n",
    "# hotel df of continuos variables in the data set\n",
    "hotelCont = hotel[hotel_continuous]\n",
    "\n",
    "# Mean Normalization of the Continous Variables -  still contains large outliers pictured in graphs below\n",
    "hotelCont_mean_normed = (hotelCont-hotelCont.mean())/(hotelCont.std())\n",
    "\n",
    "# list of categorical attributes\n",
    "hotel_categoricals =  ['hotel','is_canceled','deposit_type','agent','company','customer_type',\n",
    "                       'reservation_status','meal', 'country', 'market_segment', 'distribution_channel', 'is_repeated_guest',\n",
    "                       'reserved_room_type', 'assigned_room_type', 'stays_in_week_nights_cat','stays_in_weekend_nights_cat']\n",
    "\n",
    "# setting categoricals as that type.\n",
    "for cat in hotel_categoricals:\n",
    "  hotel[cat] = hotel[cat].astype('category')\n",
    "\n",
    "# hotel df of categorical variables\n",
    "hotelCats = hotel[hotel_categoricals]\n",
    "\n",
    "\n",
    "# converting reservation_status_date to datetime\n",
    "hotel['reservation_status_date'] = pd.to_datetime(hotel['reservation_status_date'])\n",
    "\n",
    "\n",
    "# hotel df of datetime variables\n",
    "hotelDates = hotel.select_dtypes(include=['datetime64'])\n",
    "\n",
    "# Removing outliers greater than 5\n",
    "hotel_nol = hotelCont_mean_normed[(np.abs(hotelCont_mean_normed) < 5).all(axis=1)]\n",
    "\n",
    "\n",
    "# Grabbing indices of the non-outlier rows\n",
    "no_outlier_indices = pd.DataFrame(hotel_nol.index)\n",
    "no_outlier_indices.rename(columns={0: \"indices\"}, inplace=True)\n",
    "# no_outlier_indices\n",
    "\n",
    "# This data set has removed the outliers and un-normed the data so that we can use it without snooping on our test data\n",
    "hotel_no_outliers = pd.concat([hotelCont, hotelCats, hotelDates], axis = 1, join = 'inner')\n",
    "hotel_no_outliers = hotel_no_outliers.iloc[no_outlier_indices.indices,]\n",
    "\n",
    "\n",
    "# Changing Company to be a boolean variable. Running into issues when we split train/test that some of these are too rare to be populated\n",
    "company_adjust = pd.DataFrame(hotel_no_outliers['company'])\n",
    "company_adjust.replace(to_replace='Unknown', value = 0, inplace=True)\n",
    "company_adjust = company_adjust.astype('float64')\n",
    "\n",
    "# https://stackoverflow.com/questions/45790889/replace-non-zero-values-in-a-pandas-dataframe-with-1\n",
    "company_adjust = company_adjust.astype(bool).astype(int)\n",
    "#company_adjust.head(20)\n",
    "\n",
    "# Changing Agent to be a boolean variable. Running into issues when we split train/test that some of these are too rare to be populated\n",
    "agent_adjust = pd.DataFrame(hotel_no_outliers['agent'])\n",
    "agent_adjust.replace(to_replace='Unknown', value = 0, inplace=True)\n",
    "agent_adjust = agent_adjust.astype(bool).astype(int)\n",
    "#agent_adjust.head(10)\n",
    "\n",
    "# Create Right Room\n",
    "trial_df = hotel_no_outliers\n",
    "trial_df['assigned_room_type'].dtype,trial_df['reserved_room_type'].dtype\n",
    "\n",
    "trial_df['right_room'] = np.where((trial_df['reserved_room_type'].astype(str)==trial_df['assigned_room_type'].astype(str)), 1, 0)\n",
    "\n",
    "# Previous Cancel to Category\n",
    "PrevCancel_adjust = pd.DataFrame(hotel_no_outliers['previous_cancellations'])\n",
    "PrevCancel_adjust = PrevCancel_adjust.astype(bool).astype(int)\n",
    "PrevCancel_adjust.columns = ['prev_canceled']\n",
    "\n",
    "\n",
    "lt_cat = pd.DataFrame(hotel_no_outliers['lead_time'])\n",
    "# Lead time categories 0 days to 1 week, 1 week to 1 month, 1 month to 6 months, greater than 6 months\n",
    "lt_cat = pd.cut(lt_cat['lead_time'], bins=[0,7,31,180,737],\n",
    "                labels=['booked_week', 'booked_month', 'booked_6_months', 'booked_long'])\n",
    "\n",
    "# Country Categorizing\n",
    "country_cat = pd.DataFrame(hotel_no_outliers['country'])\n",
    "# countries changed to top 10 and others\n",
    "country_cat['c_group'] = country_cat['country'].apply(lambda x: 'top_ten' \n",
    "                                                      if x in ['PRT','GBR','BEL', 'NLD', 'DEU','ESP', 'ITA', 'IRL', 'BRA', 'FRA'] \n",
    "                                                      else 'other_country')\n",
    "trial_df = hotel_no_outliers.join(country_cat['c_group'])\n",
    "\n",
    "# Dropping variables and adding in the new ones. \n",
    "# Also creates the dummy data set which contains the one hot encoded cats\n",
    "dummy_trial = trial_df.drop(['company','agent','is_canceled', 'reservation_status',\n",
    "                          'lead_time', 'country', 'previous_cancellations'], axis = 1)\n",
    "\n",
    "dummy_trial['company'] = company_adjust\n",
    "dummy_trial['agent'] = agent_adjust\n",
    "dummy_trial['right_room'] = trial_df['right_room']\n",
    "dummy_trial['previous_canceled'] = PrevCancel_adjust['prev_canceled']\n",
    "dummy_trial['lead_time'] = lt_cat\n",
    "dummy_trial = pd.get_dummies(dummy_trial, drop_first=True)\n",
    "\n",
    "\n",
    "#((115232, 37), (115232, 67))\n",
    "# Quality check on merged data\n",
    "trial_df.shape, dummy_trial.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and prepare class variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We are going to predict cancelations (is_canceled), either a reservation canceled or did not cancel. This is a binary response, and is categorical, so this is a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> is_canceled, our target for the classification task, was not balanced and we did not do any adjustment of the class variable because we have data directly from the hotels' databases for a 3 year period. Also, this is a large enough sample that we feel it is representative of the population of the hotels' records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use proper variable representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Pre-processing methods for dimensionality reduction, scaling, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove variables that are not needed/useful for analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe the final dataset that is used for classification/regression (descriptions of variables included)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose and explain your evaluation metrics you will use. Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For our classification task, the target variable of cancelations versus non-cancelations is unbalanced (~30/70) so it will be a better choice to use F1 score - which is the harmonic mean of Recall and Precision - versus the single metrics themselves. We will also use accuracy to compare our model runs. \n",
    "\n",
    "> For our regression prediction we are going to predict length of stay (length_of_stay). We chose regression because the number of nights guests stayed at the hotel length_of_stay is a continous variable.   We will compare against the metrics of RMSE or mean absolute error. We will use RMSE because this metric penalizes large errors in the model (due to squaring first) and having a large error on a predicted length of stay may be catastrophic to the businesses uses of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose the method you will use for dividing your data into training and testing splits (i.e., are you using Stratified 10-fold cross validation? Why?) Explain why your chosen method is appropriate or use more than one method as appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We will measure the effectiveness of this classification model by using Stratified 10-fold cross validation. The count of cancelations versus non-cancelations is unbalanced (~30/70) and we want to make sure that each fold maintains the same balance as the source data.\n",
    "\n",
    "> We will measure the effectiveness of this regression model by using 10-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Classification Task: KNN, Logistic, NB\n",
    "\n",
    "\n",
    "> Regression Task: KNN, OLS, Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms! (Hyperparameter tuning and gridsearchcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> List of Visualizations:\n",
    ">    - ROC (Classification) \n",
    "\n",
    ">    - KNN Viz https://towardsdatascience.com/knn-visualization-in-just-13-lines-of-code-32820d72c6b6\n",
    "\n",
    ">    - SE Link for Regression Viz https://stats.stackexchange.com/questions/89747/how-to-describe-or-visualize-a-multiple-linear-regression-model\n",
    "\n",
    ">    - Confusion Matrices as heat maps (Classification) https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea\n",
    "\n",
    ">    - Correlation Matrix heat maps (Regression)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation Part 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Better on Metrics?\n",
    "\n",
    "> Better on Time?\n",
    "\n",
    "> Sparse vs Non\n",
    "\n",
    "> Model Specific https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms, https://discuss.analyticsvidhya.com/t/which-one-to-use-randomforest-vs-svm-vs-knn/2897/3, https://towardsdatascience.com/comparative-study-on-classic-machine-learning-algorithms-24f9ff6ab222"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Is the difference significant with 95% confidence? proper statistical comparison methods. You must use statistical comparison techniquesâ€”be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparing on Statistics: https://machinelearningmastery.com/statistical-significance-tests-for-comparing-machine-learning-algorithms/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation Part 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task\n",
    "\n",
    "### Do we need to this for every model iteration? ASK HIM ON THURSDAY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deployment NEIL GOT THIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How useful is your model for interested parties (i.e., the companies or organizations that might want to use it for prediction)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Have a discussion about scope of use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How would you measure the model's value if it was used by these parties?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  How would your deploy your model for interested parties? What other datashould be collected? How often would the model need to be updated, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceptional Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
