{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### DS7337 NLP - HW 4\n",
    " #### Neil Benson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Homework4\n",
    "\n",
    " <u>**HW 4:**</u>\n",
    "\n",
    " [book link](http://www.nltk.org/book/)\n",
    "\n",
    " 1.\tRun one of the part-of-speech (POS) taggers available in Python.\n",
    "     - a. Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "     - b. Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n",
    "\n",
    "\n",
    " 2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "     - a. Does it produce the same or different output?\n",
    "     - b. Explain any differences as best you can.\n",
    "\n",
    "\n",
    " 3.\tIn a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "     - a. Looking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "     - b. Now run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    "     - c. Explain any differences between the two taggers and your manual tagging as much as you can.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "\n",
    "\n",
    "# spacy\n",
    "import spacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/bensonnd/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "sp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Global Variables #####\n",
    "toktok = ToktokTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run one of the part-of-speech (POS) taggers available in Python.\n",
    "Using nltk to POS tag the two different sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1 with nltk has 24 tokens, including punctuation:\n",
      "  ['Similarly', ',', 'when', 'someone', 'is', 'failing', ',', 'the', 'tendency', 'is', 'to', 'get', 'on', 'a', 'downward', 'spiral', 'that', 'can', 'even', 'become', 'a', 'self-fulfilling', 'prophecy', '.'] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n",
      "sentence2 with nltk has 14 tokens, including punctuation:\n",
      "  ['If', 'you', 'really', 'look', 'closely', ',', 'most', 'overnight', 'successes', 'took', 'a', 'long', 'time', '.'] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"\"\"Similarly, when someone is failing, the tendency is to get on a downward spiral that can even become a self-fulfilling prophecy.\"\"\"\n",
    "sentence2 = \"\"\"If you really look closely, most overnight successes took a long time.\"\"\"\n",
    "\n",
    "loc = locals()\n",
    "\n",
    "sentences = {key: value for key, value in loc.items() if key.startswith(\"sentence\")}\n",
    "\n",
    "\n",
    "# tokenizing the sentences - nltk\n",
    "tokenized_sentences_nltk = {\n",
    "    name: toktok.tokenize(sentence) for name, sentence in sentences.items()\n",
    "}\n",
    "\n",
    "\n",
    "# examining the length of each - nltk tokenized sentence\n",
    "for name, ts in tokenized_sentences_nltk.items():\n",
    "    print(\n",
    "        f\"{name} with nltk has {len(ts)} tokens, including punctuation:\\n  {ts} \\n\\n\",\n",
    "        \"-\" * 40,\n",
    "        \"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1 has the following nltk POS tags:\n",
      "  [('Similarly', 'RB'), (',', ','), ('when', 'WRB'), ('someone', 'NN'), ('is', 'VBZ'), ('failing', 'VBG'), (',', ','), ('the', 'DT'), ('tendency', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('get', 'VB'), ('on', 'IN'), ('a', 'DT'), ('downward', 'JJ'), ('spiral', 'NN'), ('that', 'WDT'), ('can', 'MD'), ('even', 'RB'), ('become', 'VB'), ('a', 'DT'), ('self-fulfilling', 'JJ'), ('prophecy', 'NN'), ('.', '.')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n",
      "sentence2 has the following nltk POS tags:\n",
      "  [('If', 'IN'), ('you', 'PRP'), ('really', 'RB'), ('look', 'VB'), ('closely', 'RB'), (',', ','), ('most', 'JJS'), ('overnight', 'JJ'), ('successes', 'NNS'), ('took', 'VBD'), ('a', 'DT'), ('long', 'JJ'), ('time', 'NN'), ('.', '.')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# POS tagging using nltk\n",
    "pos_tags_nltk = {\n",
    "    name: nltk.pos_tag(ts) for name, ts in tokenized_sentences_nltk.items()\n",
    "}\n",
    "\n",
    "\n",
    "for name, pos_tags in pos_tags_nltk.items():\n",
    "    print(\n",
    "        f\"{name} has the following nltk POS tags:\\n  {pos_tags} \\n\\n\", \"-\" * 40, \"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "Using spacy to POS tag the two different sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1 with spacy has 26 tokens, including punctuation:\n",
      "  Similarly, when someone is failing, the tendency is to get on a downward spiral that can even become a self-fulfilling prophecy. \n",
      "\n",
      " ---------------------------------------- \n",
      "\n",
      "sentence2 with spacy has 14 tokens, including punctuation:\n",
      "  If you really look closely, most overnight successes took a long time. \n",
      "\n",
      " ---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function to extract spacy objects\n",
    "def sp_pos(sentence):\n",
    "    return list(zip([str(i) for i in sentence], [i.tag_ for i in sentence]))\n",
    "\n",
    "\n",
    "# tokenizing the sentences - spacy\n",
    "tokenized_sentences_spacy = {name: sp(sentence) for name, sentence in sentences.items()}\n",
    "\n",
    "\n",
    "# examining the length of each - spacy tokenized sentence\n",
    "for name, ts in tokenized_sentences_spacy.items():\n",
    "    print(\n",
    "        f\"{name} with spacy has {len(ts)} tokens, including punctuation:\\n  {ts} \\n\\n\",\n",
    "        \"-\" * 40,\n",
    "        \"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1 has the following spacy POS tags:\n",
      "  [('Similarly', 'RB'), (',', ','), ('when', 'WRB'), ('someone', 'NN'), ('is', 'VBZ'), ('failing', 'VBG'), (',', ','), ('the', 'DT'), ('tendency', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('get', 'VB'), ('on', 'IN'), ('a', 'DT'), ('downward', 'JJ'), ('spiral', 'NN'), ('that', 'WDT'), ('can', 'MD'), ('even', 'RB'), ('become', 'VB'), ('a', 'DT'), ('self', 'NN'), ('-', 'HYPH'), ('fulfilling', 'VBG'), ('prophecy', 'NN'), ('.', '.')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n",
      "sentence2 has the following spacy POS tags:\n",
      "  [('If', 'IN'), ('you', 'PRP'), ('really', 'RB'), ('look', 'VBP'), ('closely', 'RB'), (',', ','), ('most', 'RBS'), ('overnight', 'JJ'), ('successes', 'NNS'), ('took', 'VBD'), ('a', 'DT'), ('long', 'JJ'), ('time', 'NN'), ('.', '.')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# POS tagging using spacy\n",
    "pos_tags_spacy = {name: sp_pos(ts) for name, ts in tokenized_sentences_spacy.items()}\n",
    "\n",
    "\n",
    "for name, pos_tags in pos_tags_spacy.items():\n",
    "    print(\n",
    "        f\"{name} has the following spacy POS tags:\\n  {pos_tags} \\n\\n\", \"-\" * 40, \"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing nltk and spacy POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk and spacy POS tagged 0 sentence(s) as the same. ['sentence1', 'sentence2'] were not tagged the same.\n"
     ]
    }
   ],
   "source": [
    "# finding the same POS tags between the twoo\n",
    "same_pos_tags = {\n",
    "    k: pos_tags_nltk[k]\n",
    "    for k in pos_tags_nltk\n",
    "    if k in pos_tags_spacy and pos_tags_nltk[k] == pos_tags_spacy[k]\n",
    "}\n",
    "\n",
    "\n",
    "# finding different POS tags\n",
    "different_pos_tags = {\n",
    "    k: pos_tags_nltk[k] for k in set(pos_tags_nltk) - set(same_pos_tags)\n",
    "}\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"nltk and spacy POS tagged {len(same_pos_tags)} sentence(s) as the same. {list(different_pos_tags.keys())} were not tagged the same.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1 has the following POS tag differences:\n",
      "  [('self-fulfilling', 'JJ'), ('self', 'NN'), ('-', 'HYPH'), ('fulfilling', 'VBG')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n",
      "sentence2 has the following POS tag differences:\n",
      "  [('look', 'VB'), ('most', 'JJS'), ('look', 'VBP'), ('most', 'RBS')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# function to get difference of two lists so we can see the\n",
    "def diff(li1, li2):\n",
    "    li_dif = [i for i in li1 + li2 if i not in li1 or i not in li2]\n",
    "    return li_dif\n",
    "\n",
    "\n",
    "pos_tags = defaultdict(list)\n",
    "\n",
    "\n",
    "# combining the POS tagging from nltk and spacy to the same dictionary for comparison\n",
    "for key, value in pos_tags_nltk.items():\n",
    "    pos_tags[key].append(value)\n",
    "\n",
    "for key, value in pos_tags_spacy.items():\n",
    "    pos_tags[key].append(value)\n",
    "\n",
    "    \n",
    "# comparing the POS tagging differences\n",
    "pos_tags_diff = {k: diff(pos[0], pos[1]) for k, pos in pos_tags.items()}\n",
    "\n",
    "for name, diffs in pos_tags_diff.items():\n",
    "    print(\n",
    "        f\"{name} has the following POS tag differences:\\n  {diffs} \\n\\n\",\n",
    "        \"-\" * 40,\n",
    "        \"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is evident that the POS taggers treat words differently for each of the two sentences.\n",
    "\n",
    " For the first sentence, nltk treats `self-fulfilling` as a single word `('self-fulfilling', 'JJ')`, whereas spacy tags `self`, `-`, `fulfilling` separately as `('self', 'NN'), ('-', 'HYPH'), ('fulfilling', 'VBG')`.\n",
    " This can be traced all the way to the tokenizer for each. nltk had 24 tokens, while spacy had 26.\n",
    "\n",
    " For the second sentence, treats `look` and `most` as `('look', 'VB'), ('most', 'JJS')` while spacy treats them as `('look', 'VBP'), ('most', 'RBS')`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "Comparing NLTK vs spacy vs manual tagging with the latest news snippet.  \n",
    "News article: https://www.cnn.com/2021/06/15/weather/arizona-smoke-record-temperatures-wildfire/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual POS tagging\n",
    "news_sentence_manual = [\n",
    "    (\"Wildfire\", \"NN\"),\n",
    "    (\"smoke\", \"NN\"),\n",
    "    (\"could\", \"MD\"),\n",
    "    (\"keep\", \"VB\"),\n",
    "    (\"Phoenix\", \"NNP\"),\n",
    "    (\"from\", \"IN\"),\n",
    "    (\"reaching\", \"VBG\"),\n",
    "    (\"a\", \"DT\"),\n",
    "    (\"record\", \"NN\"),\n",
    "    (\"high\", \"JJ\"),\n",
    "    (\"temperature\", \"NN\"),\n",
    "    (\"Tuesday\", \"NNP\"),\n",
    "    (\".\", \".\"),\n",
    "]\n",
    "\n",
    "# the sentence to compare to with nltk and spacy\n",
    "news_sentence = \"\"\"Wildfire smoke could keep Phoenix from reaching a record high temperature Tuesday.\"\"\"\n",
    "\n",
    "sentences = {\"news_sentence\": news_sentence}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_sentence with nltk has 13 tokens, including punctuation:\n",
      "  ['Wildfire', 'smoke', 'could', 'keep', 'Phoenix', 'from', 'reaching', 'a', 'record', 'high', 'temperature', 'Tuesday', '.'] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n",
      "news_sentence with spacy has 13 tokens, including punctuation:\n",
      "  Wildfire smoke could keep Phoenix from reaching a record high temperature Tuesday. \n",
      "\n",
      " ---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tokenizing the sentences - nltk\n",
    "tokenized_sentences_nltk_news = {\n",
    "    name: toktok.tokenize(sentence) for name, sentence in sentences.items()\n",
    "}\n",
    "\n",
    "# examining the length of each - nltk tokenized sentence\n",
    "for name, ts in tokenized_sentences_nltk_news.items():\n",
    "    print(\n",
    "        f\"{name} with nltk has {len(ts)} tokens, including punctuation:\\n  {ts} \\n\\n\",\n",
    "        \"-\" * 40,\n",
    "        \"\\n\",\n",
    "    )\n",
    "\n",
    "# tokenizing the sentences - spacy\n",
    "tokenized_sentences_spacy_news = {\n",
    "    name: sp(sentence) for name, sentence in sentences.items()\n",
    "}\n",
    "\n",
    "# examining the length of each - spacy tokenized sentence\n",
    "for name, ts in tokenized_sentences_spacy_news.items():\n",
    "    print(\n",
    "        f\"{name} with spacy has {len(ts)} tokens, including punctuation:\\n  {ts} \\n\\n\",\n",
    "        \"-\" * 40,\n",
    "        \"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_sentence has the following nltk POS tags:\n",
      "  [('Wildfire', 'NNP'), ('smoke', 'NN'), ('could', 'MD'), ('keep', 'VB'), ('Phoenix', 'NNP'), ('from', 'IN'), ('reaching', 'VBG'), ('a', 'DT'), ('record', 'NN'), ('high', 'JJ'), ('temperature', 'NN'), ('Tuesday', 'NNP'), ('.', '.')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n",
      "news_sentence has the following spacy POS tags:\n",
      "  [('Wildfire', 'NN'), ('smoke', 'NN'), ('could', 'MD'), ('keep', 'VB'), ('Phoenix', 'NNP'), ('from', 'IN'), ('reaching', 'VBG'), ('a', 'DT'), ('record', 'NN'), ('high', 'JJ'), ('temperature', 'NN'), ('Tuesday', 'NNP'), ('.', '.')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# POS tagging using nltk\n",
    "pos_tags_nltk_news = {\n",
    "    name: nltk.pos_tag(ts) for name, ts in tokenized_sentences_nltk_news.items()\n",
    "}\n",
    "\n",
    "for name, pos_tags in pos_tags_nltk_news.items():\n",
    "    print(\n",
    "        f\"{name} has the following nltk POS tags:\\n  {pos_tags} \\n\\n\", \"-\" * 40, \"\\n\",\n",
    "    )\n",
    "\n",
    "# POS tagging using spacy\n",
    "pos_tags_spacy_news = {\n",
    "    name: sp_pos(ts) for name, ts in tokenized_sentences_spacy_news.items()\n",
    "}\n",
    "\n",
    "for name, pos_tags in pos_tags_spacy_news.items():\n",
    "    print(\n",
    "        f\"{name} has the following spacy POS tags:\\n  {pos_tags} \\n\\n\", \"-\" * 40, \"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing nltk and spacy POS tagging - News Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nltk and spacy POS tagged 0 sentence(s) as the same. ['news_sentence'] were not tagged the same.\n"
     ]
    }
   ],
   "source": [
    "# finding the same POS tags\n",
    "same_pos_tags_news = {\n",
    "    k: pos_tags_nltk_news[k]\n",
    "    for k in pos_tags_nltk_news\n",
    "    if k in pos_tags_spacy_news and pos_tags_nltk_news[k] == pos_tags_spacy_news[k]\n",
    "}\n",
    "\n",
    "# finding different POS tags\n",
    "different_pos_tags_news = {\n",
    "    k: pos_tags_nltk_news[k] for k in set(pos_tags_nltk_news) - set(same_pos_tags_news)\n",
    "}\n",
    "\n",
    "print(\n",
    "    f\"nltk and spacy POS tagged {len(same_pos_tags_news)} sentence(s) as the same. {list(different_pos_tags_news.keys())} were not tagged the same.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_sentence has the following POS tag differences between nltk and spacy:\n",
      "  [('Wildfire', 'NNP'), ('Wildfire', 'NN')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "pos_tags_manual = {\"news_sentence\": news_sentence_manual}\n",
    "\n",
    "pos_tags_news = defaultdict(list)\n",
    "\n",
    "# combining the POS tagging from nltk and spacy and manual to the same dictionary for comparison\n",
    "for key, value in pos_tags_nltk_news.items():\n",
    "    pos_tags_news[key].append(value)\n",
    "\n",
    "for key, value in pos_tags_spacy_news.items():\n",
    "    pos_tags_news[key].append(value)\n",
    "\n",
    "# comparing the POS tagging differences between nltk and spacy\n",
    "pos_tags_diff_news = {k: diff(pos[0], pos[1]) for k, pos in pos_tags_news.items()}\n",
    "\n",
    "for name, diffs in pos_tags_diff_news.items():\n",
    "    print(\n",
    "        f\"{name} has the following POS tag differences between nltk and spacy:\\n  {diffs} \\n\\n\",\n",
    "        \"-\" * 40,\n",
    "        \"\\n\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Both nltk and spacy tokenize the news sentence as the same, but tag `Wildfire` differently as both `('Wildfire', 'NNP')` from nltk and `('Wildfire', 'NN')` from spacy.\n",
    " While spacy treats `Wildfire` as a singular noun, nltk tags it as proper noun. In this case, it's just the beginning of the sentence,\n",
    " which is why it's capitalized, but it's not a proper noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing nltk, spacy to manual POS tagging - News Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tags_news_man_nltk = defaultdict(list)\n",
    "pos_tags_news_man_spcy = defaultdict(list)\n",
    "\n",
    "# adding in the manual tagging to compare to nltk and spacy\n",
    "for key, value in pos_tags_manual.items():\n",
    "    pos_tags_news_man_nltk[key].append(value)  # add manual to compare to nltk\n",
    "    pos_tags_news_man_spcy[key].append(value)  # add manual to compare to spacy\n",
    "\n",
    "for key, value in pos_tags_nltk_news.items():\n",
    "    pos_tags_news_man_nltk[key].append(value)  # add nltk to compare to manual\n",
    "\n",
    "for key, value in pos_tags_spacy_news.items():\n",
    "    pos_tags_news_man_spcy[key].append(value)  # add spacy to compare to manual\n",
    "\n",
    "# comparing the POS tagging differences\n",
    "pos_tags_diff_news_man_nltk = {\n",
    "    k: diff(pos[0], pos[1]) for k, pos in pos_tags_news_man_nltk.items()\n",
    "}\n",
    "pos_tags_diff_news_man_spcy = {\n",
    "    k: diff(pos[0], pos[1]) for k, pos in pos_tags_news_man_spcy.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news_sentence has the following POS tag differences between manual and nltk:\n",
      "  [('Wildfire', 'NN'), ('Wildfire', 'NNP')] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n",
      "news_sentence has the following POS tag differences between manual and spacy:\n",
      "  [] \n",
      "\n",
      " ---------------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking the difference between nltk and manual POS tagging\n",
    "for name, diffs in pos_tags_diff_news_man_nltk.items():\n",
    "    print(\n",
    "        f\"{name} has the following POS tag differences between manual and nltk:\\n  {diffs} \\n\\n\",\n",
    "        \"-\" * 40,\n",
    "        \"\\n\",\n",
    "    )\n",
    "\n",
    "# checking the difference between spacy and manual POS tagging\n",
    "for name, diffs in pos_tags_diff_news_man_spcy.items():\n",
    "    print(\n",
    "        f\"{name} has the following POS tag differences between manual and spacy:\\n  {diffs} \\n\\n\",\n",
    "        \"-\" * 40,\n",
    "        \"\\n\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Because I treated `Wildfire` as a singular noun, similar to spacy, spacy had 0 differences in our POS tagging.\n",
    " However, because nltk treats `Wildfire` as a proper noun, we had one difference, as noted above, in our POS tagging."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
